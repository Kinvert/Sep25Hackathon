[base]
package = ocean
env_name = puffer_drone_pp
policy_name = Policy
rnn_name = Recurrent

[policy]
hidden_size = 256

[rnn]
input_size = 256
hidden_size = 256

[vec]
num_envs = 24

[env]
num_envs = 24 # 16
num_drones = 64 # 64
max_rings = 10

box_base_density = 50.0
box_k_growth = 0.14650412647921088

dist_decay = 0.5

grip_k_decay = 0.08446181692326117
grip_k_max = 20.0
grip_k_min = 1.0

pos_const = 0.5045867914708699
pos_penalty = 0.001

reward_grip = 0.8652832475760078
reward_hover = 0.29448058516306386
reward_ho_drop = 0.25

reward_max_dist = 65.0
reward_min_dist = 2.358100729152874

w_approach = 2.165579243246008
w_position = 0.5636394718028079
w_stability = 1.033283729086403
w_velocity = 0.0

[train]
adam_beta1 = 0.8380607756657964
adam_beta2 = 0.9991880618184554
adam_eps = 1.698580366234846e-07
anneal_lr = true
batch_size = auto
bptt_horizon = 64
checkpoint_interval = 200
clip_coef = 0.19212875622700953
ent_coef = 0.0973185006981391
gae_lambda = 0.9732262407199983
gamma = 0.9732065267543796
learning_rate = 0.006298827725400678
#learning_rate = 0.005
max_grad_norm = 3.690369283073297
max_minibatch_size = 32768
minibatch_size = 8192
prio_alpha = 0.25112976193955017
prio_beta0 = 0.9897631408784592
total_timesteps = 200_000_000
update_epochs = 1
#use_rnn = false
vf_clip_coef = 0.1
vf_coef = 3.017692222421826
vtrace_c_clip = 1.4181363431824252
vtrace_rho_clip = 2.8484309983367275

[sweep]
method = Protein
metric = perfect_deliv
goal = maximize
downsample = 0

[sweep.env.w_position]
distribution = uniform
min = 0.0
max = 1.5
mean = 0.56
scale = auto

[sweep.env.w_velocity]
distribution = uniform
min = 0.0
max = 1.5
mean = 0.001
scale = auto

[sweep.env.w_stability]
distribution = uniform
min = 0.0
max = 2.5
mean = 1.03
scale = auto

[sweep.env.w_approach]
distribution = uniform
min = 0.0
max = 2.5
mean = 2.17
scale = auto

[sweep.env.reward_min_dist]
distribution = uniform
min = 0.1
max = 5.0
mean = 2.36
scale = auto

[sweep.env.dist_decay]
distribution = uniform
min = 0.1
max = 1.0
mean = 0.5
scale = auto

[sweep.env.pos_const]
distribution = uniform
min = 0.001
max = 1.0
mean = 0.5
scale = auto

[sweep.env.pos_penalty]
distribution = uniform
min = 0.0001
max = 0.25
mean = 0.002
scale = auto

[sweep.env.grip_k_max]
distribution = uniform
min = 10.0
max = 20.0
mean = 15.0
scale = auto

[sweep.env.grip_k_decay]
distribution = uniform
min = 0.01
max = 0.15
mean = 0.085
scale = auto

[sweep.env.box_k_growth]
distribution = uniform
min = 0.005
max = 0.5
mean = 0.15
scale = auto

[sweep.env.reward_hover]
distribution = uniform
min = 0.0
max = 0.5
mean = 0.29
scale = auto

[sweep.env.reward_grip]
distribution = uniform
min = 0.0
max = 1.0
mean = 0.87
scale = auto

[sweep.env.reward_ho_drop]
distribution = uniform
min = 0.1
max = 0.5
mean = 0.25
scale = auto
